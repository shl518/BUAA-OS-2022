---
title: 2022操作系统Lab4实验报告
date: 2022-06-24 15:57:42
tags: 操作系统
---

## Lab4实验报告

### 1.1 思考题

**Thinking 4.1**. *思考并回答下面的问题：*

- *内核在保存现场的时候是如何避免破坏通用寄存器的？*

:label:**答**：查阅相关代码，发现其实在Lab3的时候我们就已经见识到了这个问题的答案，那就是通过SAVE_ALL宏来保存用户态的所有寄存器到栈帧里。在Lab3的handle_int函数里我们就可以见到他的身影，之后如果再使用这些通用寄存器并进行改写，也不会对已经存储的值造成影响。

```asm
NESTED(handle_int, TF_SIZE, sp)
.set	noat
nop

SAVE_ALL #在这里在这里在这里,我将用户态的所有寄存器到栈帧里
CLI
.set	at
mfc0	t0, CP0_CAUSE
mfc0	t2, CP0_STATUS
and	t0, t2

andi	t1, t0, STATUSF_IP4
bnez	t1, timer_irq
nop
END(handle_int)
```

- *系统陷入内核调用后可以直接从当时的$a0-$a3参数寄存器中得到用户调用msyscall留下的信息吗？*

```asm
	lw a0, TF_REG4(sp) #a0
	lw a1, TF_REG5(sp) #a1
	lw a2, TF_REG6(sp) #a2
	lw a3, TF_REG7(sp) #a3
	addiu sp, sp, -24
	sw t3, 16(sp)
	sw t4, 20(sp)
    
    
    jalr    t2    #跳转到对应的系统调用函数
    nop
```



:label:**答**：可以，阅读代码我们可以发现在handle_sys函数里，msyscall里的6个参数，前四个被保存在了a0-a3，后两个保存在了栈内8字节空间内。紧接着handle_sys函数执行内核态对应的系统调用，a0−a3寄存器的值没有被改变过，因此可以直接使用。

- *我们是怎么做到让sys开头的函数“认为”我们提供了和用户调用msyscall时同样的参数的？*

:label:**答**：这个问题其实可以用上一个问题的答案来解释，原因在于使用了handle_sys函数将msyscall前四个参数放在对应的a0-a3寄存器上，后两个参数存在栈上的相同位置。

- *内核处理系统调用的过程对Trapframe做了哪些更改？这种修改对应的用户态的变化是？*

```asm
lw		t0, TF_EPC(sp)
addiu	t0, t0, 4 #EPC = EPC + 4
sw		t0, TF_EPC(sp)
```

:label:**答**：在handle_sys代码里可以找到答案，即修改了EPC的值，用户态返回的时候可以继续执行下一条指令

**Thinking 4.2**. 思考下面的问题，并对这个问题谈谈你的理解： 请回顾 lib/env.c 文件中 `mkenvid()` 函数的实现，该函数不会返回 0，请结合系统调用和 IPC 部分的实现 与 `envid2env()` 函数的行为进行解释。

:label:**答**：因为envid2env里面对于id=0的进程返回当前进程curenv，我们要用envid = 0特殊标识curenv。有了这个特殊标识以后就向envid2env传入0而快速的得到当前进程的env块。

**另一个更重要的原因**在于实现fork.c过程中，我们要求子进程返回`newenvid = 0`而父进程`newenvid !=0`（阅读代码我们发现父进程返回的newenvid其实是子进程的真实envid）。`mkenvid()` 函数不会返回 0的原因在于不能让任何一个进程的envid = 0，否则在返回newenvid的时候就可能父进程也返回0，子进程也返回0，无法区分父子进程。



**Thinking 4.3**. *思考下面的问题，并对这两个问题谈谈你的理解：*

- *子进程完全按照 fork() 之后父进程的代码执行，说明了什么？*

:label:**答**：说明子进程和父进程共享代码段。

- *但是子进程却没有执行 fork() 之前父进程的代码，又说明了什么？*

:label:**答**：说明子进程恢复到的上下文位置是fork函数

**Thinking 4.4**. *关于 fork 函数的两个返回值，下面说法正确的是：*

*A、fork 在父进程中被调用两次，产生两个返回值*

*B、fork 在两个进程中分别被调用一次，产生两个不同的返回值*

*C、fork 只在父进程中被调用了一次，在两个进程中各产生一个返回值*

*D、fork 只在子进程中被调用了一次，在两个进程中各产生一个返回值*

:label:**答**：C



**Thinking 4.5**. *我们并不应该对所有的用户空间页都使用`duppage`进行映射。那么究竟哪些用户空间页应该映射，哪些不应该呢？ 请结合本章的后续描述、mm/pmap.c 中 `mips_vm_init` 函数进行的页面映射以及 include/mmu.h 里的内存布局图进行思考。*

![image-20220514210021387](https://note.youdao.com/yws/api/personal/file/F2B59E4132B6478E8B36A8880D1A8322?method=download&shareKey=cfa1ccb508bd72c7b0a0729d99bdfa72)

:label:**答**:

- UTOP以上的用户空间对于用户进程来说不可改变；系统空间对于每个进程来说是相同且不可改变的，因此UTOP以上空间不用进行保护；
- UXSTACKTOP - BY2PG到UXSTACKTOP的空间是用户进程的异常栈，若进行写时复制保护可能陷入死循环，因此不能被保护。
- USTACKTOP到USTACKTOP + BY2PG的空间在空间分布图上是Invalid memory，用不到所以无需保护。
- 去除上述这些，需要保护的是在0与USTACKTOP之间且在父进程中有效的页面。并且在**如下代码**中我们看到也确实如此。

```C
//fork.c
if(newenvid){
        for (i = 0; i < VPN(USTACKTOP); i++) { //0 --- USTACKTOP之间！！！！！！！！！！！！！！
            if ((((Pde *)(*vpd))[i >> 10] & PTE_V) && (((Pte *)(*vpt))[i] & PTE_V)) {
                duppage(newenvid, i);
            }
        }
        syscall_mem_alloc(newenvid, UXSTACKTOP - BY2PG, PTE_V|PTE_R);
        syscall_set_pgfault_handler(newenvid, __asm_pgfault_handler, UXSTACKTOP);
        syscall_set_env_status(newenvid, ENV_RUNNABLE);
    }
```



**Thinking 4.6**. *在遍历地址空间存取页表项时你需要使用到vpd和vpt这两个“指针的指针”，请参考 user/entry.S 和 include/mmu.h 中的相关实现，思考并回答这几个问题：*

:label:**答**：首先我们可以在mmu.h中找到他们的定义

```C
extern volatile Pte* vpt[]; 
extern volatile Pde* vpd[]; 
```

- *vpt和vpd的作用是什么？怎样使用它们？*

:label:**答**：vpt存放着二级页表，vpd存放着一级页表，使用时把它们当作数组头。对于虚拟地址va，`（*vpd）[PDX(va)]`为二级页表的物理地址，`(*vpt)[PTX(va)]`为va对应的物理页面。此外，我们在duppage里这样使用它。总而言之，我们可以通过vpt,vpd访问一级页目录与二级页表。

```C
duppage(u_int envid, u_int pn)
{
    u_int addr;
    u_int perm;
    int flag = 0;
    addr = pn << PGSHIFT;
    perm = (*vpt)[pn] & (BY2PG - 1);//使用(*vpt)[pn]取出对应页表项！！！！！！！！
    if ((perm & PTE_R) && !(perm & PTE_LIBRARY)) {
        perm |= PTE_COW;
        flag = 1;
    }
    syscall_mem_map(0, addr, envid, addr, perm);
    if (flag) syscall_mem_map(0, addr, 0, addr, perm);
    //  user_panic("duppage not implemented");
}
```

- *从实现的角度谈一下为什么进程能够通过这种方式来存取自身的页表？*

:label:**答**：

```asm
#entry.S
.globl vpt 
 vpt:     
     .word UVPT 
     .globl vpd 
vpd:     
     .word (UVPT+(UVPT>>12)*4) #自映射机制 
```

在entry.S中定义vpt，vpd,很明显这里使用了自映射机制。vpt指向了UVPT是进程页表所在之处,vpd通过自映射机制指向了`(UVPT+(UVPT>>12)*4)`,是自映射机制下的一级页表地址。通过这样的定义，进程能够通过这种方式来存取自身的页表。

- *它们是如何体现自映射设计的？*

:label:**答**：上一问已经谈到，在`entry.S`的对vpd定义里可以明显看到自映射机制的存在。

- *进程能够通过这种方式来修改自己的页表项吗？*

:label:**答**：不可以，用户进程无权限直接修改页表项。如果非要修改的话，我们在`duppage`里使用了系统调用`syscall_mem_map`的这种方式进行修改。

```C
static void duppage(u_int envid, u_int pn)
{
    u_int addr;
    u_int perm;
    int flag = 0;
    addr = pn << PGSHIFT;
    perm = (*vpt)[pn] & (BY2PG - 1);
    if ((perm & PTE_R) && !(perm & PTE_LIBRARY)) {
        perm |= PTE_COW;
        flag = 1;
    }
    syscall_mem_map(0, addr, envid, addr, perm);
    if (flag) syscall_mem_map(0, addr, 0, addr, perm);
    //上面这句话通过系统调用syscall_mem_map的方式陷入内核，进程间接通过内核修改了页表项，但是无论如何进程不能通过vpt，vpd直接修改页表项
    //  user_panic("duppage not implemented");
}
```



**Thinking 4.7**. `page_fault_handler` 函数中，你可能注意到了一个向异常处理栈复制Trapframe运行现场的过程，请思考并回答这几个问题：

- 这里实现了一个支持类似于“中断重入”的机制，而在什么时候会出现这种“中断重入”？

:label:**答**：

```asm
BUILD_HANDLER mod page_fault_handler cli
```

通过全局grep可以发现在全文中只有一处汇编调用了`page_fault_handler`，即handle_mod，而该中断处理函数与写时复制的中断缺页有关，所以间接说明 写时复制时可能导致中断重入。在用户发生写时复制引发的缺页中断并进行处理时，可能会再次发生缺页中断，从而“中断重入”。

- 内核为什么需要将异常的现场Trapframe复制到用户空间？

:label:**答**：因为指导书也提到：

**“事实上，我们的MOS操作系统按照微内核的设计理念， 尽可能地将功能实现在用户空间中，其中也包括了页写入异常的处理，因此主要的处理过程是在用户态下完成的。”**

因此我们在用户进程处理此缺页中断，需要将现场的信息保存在用户态。再具体来看，页写入异常处理会返回到entry.S中的 `__asm_pgfault_handler`函数。

这个函数在用户态下，从内核返回后，此时的栈指针是由内核设置的，处于异常处理栈中，且指向一个由内核复制好的 Trapframe 结构体的底部,**我们需要使用之前复制到异常处理栈中的TrapFrame里面的信息跳转到真正的异常处理函数**。如果之前内核没有吧现场的TrapFrame复制到异常处理栈，那么我们在这里也无法跳转到真正的异常处理函数。

```asm
__asm_pgfault_handler:
lw      a0, TF_BADVADDR(sp)
lw      t1, __pgfault_handler
jalr    t1
nop

lw      v1, TF_LO(sp)
mtlo    v1
lw      v0, TF_HI(sp)
lw      v1, TF_EPC(sp)
mthi    v0
mtc0    v1, CP0_EPC
lw      $31, TF_REG31(sp)

lw      $1, TF_REG1(sp)
lw      k0, TF_EPC(sp)
jr      k0
lw      sp, TF_REG29(sp)
```



**Thinking 4.8**. 到这里我们大概知道了这是一个由用户程序处理并由用户程序自身来恢复运行现场的过程，请思考并回答以下几个问题：

- 在用户态处理页写入异常，相比于在内核态处理有什么优势？

:label:**答**：这里应用了微内核的设计理念，具有微内核的优势即具有可扩展性，灵活性，同时具有可靠性与安全性，能够易于进行移植。

- 从通用寄存器的用途角度讨论，在可能被中断的用户态下进行现场的恢复，要如何做到不破坏现场中的通用寄存器？

:label:**答**：首先使用存放函数调用返回值的$v0, v1恢复非通用寄存器，之后通过v1恢复非通用寄存器，之后通过sp恢复通用寄存器，最后恢复$sp，保证了恢复后个寄存器值正确。

**Thinking 4.9**. *请思考并回答以下几个问题：*

- 为什么需要将`set_pgfault_handler`的调用放置在`syscall_env_alloc`之前？

:label:**答**：syscall_env_alloc过程中也可能需要进行异常处理。

- 如果放置在写时复制保护机制完成之后会有怎样的效果？

:label:**答**：此时进程给__pgfault_handler变量赋值时就会触发缺页中断，但中断处理没有设置好，故无法进行正常处理。

- 子进程是否需要对在entry.S定义的字__pgfault_handler赋值？

:label:**答**：不需要，子进程已经复制了父进程中__pgfault_handler变量值。

### 1.2 实验难点

#### 1.2.1难点一 系统调用的流程理解

系统调用是为了用户能够使用一部分内核提供的标准接口，同时不会破坏内核的正常运行。理解本次作业系统调用的流程是完成整个系统调用部分的关键。下面是帮助理解的流程图。

![image-20220531164442906](https://note.youdao.com/yws/api/personal/file/6137CDDF844746B2BDE2121A82403B4D?method=download&shareKey=f08006b63ee83ad2cf1346314a114b90)

#### 1.2.2 难点二 关于fork流程的理解

关于fork的理解是本次实验的一大难点，涉及函数很多，同时要灵活应用刚刚完成的系统调用部分。这里是我在完成fork部分填写的时候总结的fork相关流程和页写入异常的实现操作。有了这些流程的概念，脑子里会更清晰整体的思路。

![9b7db18b82d428e1a5cf819f6070007](https://note.youdao.com/yws/api/personal/file/1009BAA3F9E445159836B9D6F4A13DF7?method=download&shareKey=e5eeabc96d3183e0fb8efbecac5967a1)

### 1.3 心得体会

这次实验对于我来说感到很困难，相对于前几个单元的实验，涉及到了更多函数的填写，涉及到了更多汇编文件的理解（汇编文件的理解一直是我的弱点），尤其是后半部分的fork操作部分难度很高。在这一部分我再一次体会到思路清晰的好处，一定要自己梳理一遍各个文件，各个函数之间的关系，也要梳理一遍完成某一功能需要怎样的流程，围绕各个功能是如何实现的这一中心点来梳理会有更加清晰的思路与框架。正是因为我在课下实验中梳理了一遍fork和系统调用实现的流程，在课上考试时我明显感受到我能很快的定位某一函数的位置，某一函数的功能和这个函数与其他函数的关系与用法，我想这便是自己梳理一遍的好处所在，同时使用这个方法，我阅读代码的能力也得到了很大的提升。
